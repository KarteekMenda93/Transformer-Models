{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "QA System with BERT on Wikipedia.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io8Q_QzVGq_C"
      },
      "source": [
        "# Building a QA System with BERT on Wikipedia\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiWoyRkuGq_G"
      },
      "source": [
        "# collapse-hide \n",
        "\n",
        "# line 69 of `run_squad.py` script shows why you might need to install \n",
        "# tensorboardX if you have an older version of torch\n",
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except ImportError:\n",
        "    from tensorboardX import SummaryWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa-PT_xgGq_K"
      },
      "source": [
        "Conversely, if you're working in Colab, you can run the cell below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_98L15aGq_K"
      },
      "source": [
        "!pip install torch  torchvision -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install transformers\n",
        "!pip install wikipedia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw0B3sHwGq_N"
      },
      "source": [
        "## Fine-tuning a Transformer model for Question Answering\n",
        "\n",
        "To train a Transformer for QA with Hugging Face, we'll need\n",
        "1. to pick a specific model architecture,\n",
        "2. a QA dataset, and\n",
        "3. the training script.\n",
        "\n",
        "With these three things in hand we'll then walk through the fine-tuning process. \n",
        "\n",
        "### 1. Pick a Model\n",
        "HF identifies the following model types for the QA task: \n",
        "\n",
        "- BERT\n",
        "- distilBERT \n",
        "- ALBERT\n",
        "- RoBERTa\n",
        "- XLNet\n",
        "- XLM\n",
        "- FlauBERT\n",
        "\n",
        "\n",
        "We'll stick with the now-classic BERT model. \n",
        "\n",
        "\n",
        "### 2. QA dataset: SQuAD \n",
        "One of the most canonical datasets for QA is the Stanford Question Answering Dataset, or SQuAD, which comes in two flavors: SQuAD 1.1 and SQuAD 2.0. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgeoW8HrGq_O",
        "outputId": "4fbc3c09-d6d9-48e7-9d90-76eb611bdff4"
      },
      "source": [
        "# set path with magic\n",
        "%env DATA_DIR=./data/squad \n",
        "\n",
        "# download the data\n",
        "def download_squad(version=1):\n",
        "    if version == 1:\n",
        "        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
        "        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
        "    else:\n",
        "        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
        "        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
        "            \n",
        "download_squad(version=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: DATA_DIR=./data/squad\n",
            "--2020-05-11 21:36:52--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.109.153, 185.199.108.153, 185.199.111.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42123633 (40M) [application/json]\n",
            "Saving to: ‘./data/squad/train-v2.0.json’\n",
            "\n",
            "train-v2.0.json     100%[===================>]  40.17M  14.6MB/s    in 2.8s    \n",
            "\n",
            "2020-05-11 21:36:55 (14.6 MB/s) - ‘./data/squad/train-v2.0.json’ saved [42123633/42123633]\n",
            "\n",
            "--2020-05-11 21:36:56--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.110.153, 185.199.111.153, 185.199.108.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.110.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4370528 (4.2M) [application/json]\n",
            "Saving to: ‘./data/squad/dev-v2.0.json’\n",
            "\n",
            "dev-v2.0.json       100%[===================>]   4.17M  6.68MB/s    in 0.6s    \n",
            "\n",
            "2020-05-11 21:36:56 (6.68 MB/s) - ‘./data/squad/dev-v2.0.json’ saved [4370528/4370528]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzOS1H9oGq_Q"
      },
      "source": [
        "### 3. Fine-tuning script\n",
        "\n",
        "We've chosen a model and we've got some data. Time to train!\n",
        "\n",
        "All the standard models that HF supports have been pre-trained, which means they've all been fed massive unsupervised training sets in order to learn basic language modeling. In order to perform well at specific tasks (like question answering), they must be trained further -- fine-tuned -- on specific datasets and tasks.\n",
        "\n",
        "\n",
        "HF helpfully provides a script that fine-tunes a Transformer model on one of the SQuAD datasets, called `run_squad.py`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRacIBkFGq_R"
      },
      "source": [
        "# download the run_squad.py training script\n",
        "!curl -L -O https://raw.githubusercontent.com/huggingface/transformers/master/examples/question-answering/run_squad.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7IOrM7UGq_T"
      },
      "source": [
        "This script takes care of all the hard work that goes into fine-tuning a model and, as such, it's pretty complicated. It hosts no fewer than 45 arguments, providing an impressive amount of flexibility and utility for those who do a lot of training. We'll leave the details of this script for another day, and focus instead on the basic command to fine-tune BERT on SQuAD 1.1 or 2.0. \n",
        "\n",
        "Below are the most important arguments for the `run_squad.py` fine-tuning script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jUtA5U9Gq_T"
      },
      "source": [
        "# fine-tuning your own model for QA using HF's `run_squad.py`\n",
        "# turn flags on and off according to the model you're training\n",
        "\n",
        "cmd = [\n",
        "    'python', \n",
        "#    '-m torch.distributed.launch --nproc_per_node 2', # use this to perform distributed training over multiple GPUs\n",
        "    'run_squad.py', \n",
        "    \n",
        "    '--model_type', 'bert',                            # model type (one of the list under \"Pick a Model\" above)\n",
        "    \n",
        "    '--model_name_or_path', 'bert-base-uncased',       # specific model name of the given model type (shown, a list is here: https://huggingface.co/transformers/pretrained_models.html) \n",
        "                                                       # on first execution this initiates a download of pre-trained model weights;\n",
        "                                                       # can also be a local path to a directory with model weights\n",
        "    \n",
        "    '--output_dir', './models/bert/bbu_squad2',        # directory for model checkpoints and predictions\n",
        "    \n",
        "#    '--overwrite_output_dir',                         # use when adding output to a directory that is non-empty --\n",
        "                                                       # for instance, when training crashes midway through and you need to restart it\n",
        "    \n",
        "    '--do_train',                                      # execute the training method \n",
        "    \n",
        "    '--train_file', '$DATA_DIR/train-v2.0.json',       # provide the training data\n",
        "    \n",
        "    '--version_2_with_negative',                       # ** MUST use this flag if training on SQuAD 2.0! DO NOT use if training on SQuAD 1.1\n",
        "    \n",
        "    '--do_lower_case',                                 # ** set this flag if using an uncased model; don't use for Cased Models\n",
        "    \n",
        "    '--do_eval',                                       # execute the evaluation method on the dev set -- note: \n",
        "                                                       # if coupled with --do_train, evaluation runs after fine-tuning \n",
        "    \n",
        "    '--predict_file', '$DATA_DIR/dev-v2.0.json',       # provide evaluation data (dev set)\n",
        "    \n",
        "    '--eval_all_checkpoints',                          # evaluate the model on the dev set at each checkpoint\n",
        "    \n",
        "    '--per_gpu_eval_batch_size', '12',                 # evaluation batch size for each gpu\n",
        "    \n",
        "    '--per_gpu_train_batch_size', '12',                # training batch size for each gpu\n",
        "    \n",
        "    '--save_steps', '5000',                            # how often checkpoints (complete model snapshot) are saved \n",
        "    \n",
        "    '--threads', '8',                                  # num of CPU threads to use for converting SQuAD examples to model features\n",
        "    \n",
        "    # --- Model and Feature Hyperparameters --- \n",
        "    '--num_train_epochs', '3',                         # number of training epochs - usually 2-3 for SQuAD \n",
        "    \n",
        "    '--learning_rate', '3e-5',                         # learning rate for the default optimizer (Adam in this case)\n",
        "    \n",
        "    '--max_seq_length', '384',                         # maximum length allowed for the full input sequence \n",
        "    \n",
        "    '--doc_stride', '128'                              # used for long documents that must be chunked into multiple features -- \n",
        "                                                       # this \"sliding window\" controls the amount of stride between chunks\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q83_jkd5Gq_V"
      },
      "source": [
        "Here's what to expect when executing `run_squad.py` for the first time: \n",
        "\n",
        "1. Pre-trained model weights for the specified model type (i.e., `bert-base-uncased`) are downloaded.\n",
        "2. SQuAD training examples are converted into features (takes 15-30 minutes depending on dataset size and number of threads).\n",
        "3. Training features are saved to a cache file (so that you don't have to do this again *for this model type*).\n",
        "4. If `--do_train`, training commences for as many epochs as you specify, saving the model weights every `--save_steps` steps until training finishes. These checkpoints are saved in `[--output_dir]/checkpoint-[step number]` subdirectories.\n",
        "5. The final model weights and peripheral files are saved to `--output_dir`.\n",
        "6. If `--do_eval`, SQuAD dev examples are converted into features.\n",
        "7. Dev features are also saved to a cache file.\n",
        "8. Evaluation commences and outputs a dizzying assortment of performance scores.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBUhhqBVGq_X"
      },
      "source": [
        "#### Training in Colab\n",
        "Alternatively, you can execute training in the cell as shown below. We note that standard Colab environments only provide 12GB of RAM. Converting the SQuAD dataset to features is memory intensive and may cause the basic Colab environment to fail silently..  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "EKOjVgVnGq_a"
      },
      "source": [
        "# hide\n",
        "\n",
        "# Execute the training from a standard Jupyter Notebook \n",
        "from subprocess import PIPE, STDOUT, Popen\n",
        "\n",
        "# Live output from run_squad.py is through stderr (rather than stdout). \n",
        "# The following command runs the process and ports stderr to stdout\n",
        "p = Popen(cmd,\n",
        "          stdout=PIPE,\n",
        "          stderr=STDOUT)\n",
        "\n",
        "# Default behavior when using bash cells in jupyter is that you won't see the live output in the cell \n",
        "# -- you can only see output once the entire process has finished and then you get it all at once. \n",
        "# This is less than ideal when training models that can take hours or days of compute time! \n",
        "\n",
        "# This command combined with the above allows you to see the live output feed in the notebook, \n",
        "# though it's a bit asynchronous.\n",
        "for line in iter(p.stdout.readline, b''):\n",
        "    print(\">>> \" + line.decode().rstrip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q25VnRgFGq_d"
      },
      "source": [
        "### Training Output\n",
        "\n",
        "Successful completion of the `run_squad.py` yields a slew of output, which can be found in the `--output_dir` directory specified above. There you'll find...   \n",
        "\n",
        "Files for the model's tokenizer:\n",
        "* `tokenizer_config.json`\n",
        "* `vocab.txt`\n",
        "* `special_tokens_map.json`\n",
        "\n",
        "Files for the model itself:\n",
        "* `pytorch_model.bin`: these are the actual model weights (this file can be several GB for some models)\n",
        "* `config.json`: details of the model architecture\n",
        "\n",
        "Binary representation of the command line arguments used to train this model (so you'll never forget which arguments you used!)\n",
        "* `training_args.bin`\n",
        "\n",
        "And if you included `--do_eval`, you'll also see these files:\n",
        "* `predictions_.json`: the official best answer for each example\n",
        "* `nbest_predictions_.json`: the top n best answers for each example\n",
        "\n",
        "\n",
        "Providing the path to this directory to `AutoModel` or `AutoModelForQuestionAnswering` will load your fine-tuned model for use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JotpliGnGq_e"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "# Load the fine-tuned model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./models/bert/bbu_squad2\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"./models/bert/bbu_squad2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ngAPLMUFLW_"
      },
      "source": [
        "# The other way"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7TWS6hVGq_g"
      },
      "source": [
        "## Using a pre-fine-tuned model from the Hugging Face repository\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Let's load one of these pre-fine-tuned models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EzYJbNPGq_g"
      },
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "# executing these commands for the first time initiates a download of the \n",
        "# model weights to ~/.cache/torch/transformers/\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"deepset/bert-base-cased-squad2\") \n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/bert-base-cased-squad2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD1L0zLaGq_i"
      },
      "source": [
        "## Let's try our model!\n",
        "\n",
        "Whether you fine-tuned your own or used a pre-fine-tuned model, it's time to play with it! There are three steps to QA: \n",
        "1. tokenize the input\n",
        "2. obtain model scores\n",
        "3. get the answer span\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGUF7iE3Gq_i",
        "outputId": "3468b922-68ac-4997-893b-c97621e5cc62"
      },
      "source": [
        "question = \"Who ruled Macedonia\"\n",
        "\n",
        "context = \"\"\"Macedonia was an ancient kingdom on the periphery of Archaic and Classical Greece, \n",
        "and later the dominant state of Hellenistic Greece. The kingdom was founded and initially ruled \n",
        "by the Argead dynasty, followed by the Antipatrid and Antigonid dynasties. Home to the ancient \n",
        "Macedonians, it originated on the northeastern part of the Greek peninsula. Before the 4th \n",
        "century BC, it was a small kingdom outside of the area dominated by the city-states of Athens, \n",
        "Sparta and Thebes, and briefly subordinate to Achaemenid Persia.\"\"\"\n",
        "\n",
        "\n",
        "# 1. TOKENIZE THE INPUT\n",
        "# note: if you don't include return_tensors='pt' you'll get a list of lists which is easier for \n",
        "# exploration but you cannot feed that into a model. \n",
        "inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\") \n",
        "\n",
        "# 2. OBTAIN MODEL SCORES\n",
        "# the AutoModelForQuestionAnswering class includes a span predictor on top of the model. \n",
        "# the model returns answer start and end scores for each word in the text\n",
        "answer_start_scores, answer_end_scores = model(**inputs)\n",
        "answer_start = torch.argmax(answer_start_scores)  # get the most likely beginning of answer with the argmax of the score\n",
        "answer_end = torch.argmax(answer_end_scores) + 1  # get the most likely end of answer with the argmax of the score\n",
        "\n",
        "# 3. GET THE ANSWER SPAN\n",
        "# once we have the most likely start and end tokens, we grab all the tokens between them\n",
        "# and convert tokens back to words!\n",
        "tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the Argead dynasty'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heMMRSx9Gq_3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}